#!/usr/bin/env python3
"""
–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML —Ñ–∞–π–ª–∞
================================================================
–¶–µ–ª—å: –°—Ä–∞–≤–Ω–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ HTML vs Markdown –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
"""

import os
import sys
import json
import openai
from typing import Dict

# Try to load .env file if python-dotenv is available
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-4o-2024-08-06')

def load_prompt_and_schema():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–º–ø—Ç –∏ JSON Schema"""
    # –î–ª—è HTML –∏—Å–ø–æ–ª—å–∑—É–µ–º HTML –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ Markdown
    html_prompt_file = "input/autumna/autumna_html_prompt_v26.md"
    markdown_prompt_file = "input/autumna/autumna_markdown_prompt_v26.md"
    schema_file = "input/autumna/response_format_v26_final.json"
    
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å HTML –ø—Ä–æ–º–ø—Ç –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ Markdown
    if os.path.exists(html_prompt_file):
        prompt_file = html_prompt_file
    else:
        prompt_file = markdown_prompt_file
    
    if not os.path.exists(prompt_file):
        raise FileNotFoundError(f"–ü—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_file}")
    if not os.path.exists(schema_file):
        raise FileNotFoundError(f"JSON Schema –Ω–µ –Ω–∞–π–¥–µ–Ω: {schema_file}")
    
    with open(prompt_file, 'r', encoding='utf-8') as f:
        system_prompt = f.read()
    
    with open(schema_file, 'r', encoding='utf-8') as f:
        response_format = json.load(f)
    
    return system_prompt, response_format

def parse_html_file(html_file: str):
    """–ü–∞—Ä—Å–∏–Ω–≥ HTML —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ OpenAI API"""
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å API –∫–ª—é—á
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: export OPENAI_API_KEY=sk-...")
    
    client = openai.OpenAI(api_key=api_key)
    
    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–º–ø—Ç –∏ schema
    print("üìö –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –∏ JSON Schema...")
    prompt_file, schema_file = load_prompt_and_schema()
    
    # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã
    with open(prompt_file, 'r', encoding='utf-8') as f:
        system_prompt = f.read()
    
    with open(schema_file, 'r', encoding='utf-8') as f:
        response_format = json.load(f)
    
    # –ü—Ä–æ—á–∏—Ç–∞—Ç—å HTML —Ñ–∞–π–ª
    print(f"üìÑ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {html_file}")
    with open(html_file, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    original_size = len(html_content)
    print(f"   –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {original_size} —Å–∏–º–≤–æ–ª–æ–≤ (~{original_size // 4} —Ç–æ–∫–µ–Ω–æ–≤)")
    
    # –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è HTML (–∑–∞–º–µ–Ω–∏—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è Markdown –Ω–∞ HTML)
    # –ù–æ –ø—Ä–æ–º–ø—Ç —É–∂–µ –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å —Å –ª—é–±—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º, —Ç–∞–∫ —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–∏–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
    html_system_prompt = system_prompt.replace(
        "Markdown‚ÜíJSON extractor",
        "HTML‚ÜíJSON extractor (experimental)"
    ).replace(
        "markdown-formatted page content",
        "HTML-formatted page content"
    )
    
    # –ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ OpenAI
    print("\nü§ñ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ OpenAI API...")
    print("   ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: HTML —Ñ–∞–π–ª –Ω–∞–º–Ω–æ–≥–æ –±–æ–ª—å—à–µ Markdown!")
    print(f"   –†–∞–∑–º–µ—Ä HTML: {original_size:,} —Å–∏–º–≤–æ–ª–æ–≤ (~{original_size // 4:,} —Ç–æ–∫–µ–Ω–æ–≤)")
    
    try:
        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": html_system_prompt},
                {"role": "user", "content": f"Parse this HTML page:\n\n{html_content}"}
            ],
            response_format={"type": "json_schema", "json_schema": response_format['json_schema']},
            temperature=0
        )
        
        parsed_data = json.loads(response.choices[0].message.content)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
        usage = response.usage
        print(f"\nüìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤:")
        print(f"   –ü—Ä–æ–º–ø—Ç: {usage.prompt_tokens:,}")
        print(f"   –û—Ç–≤–µ—Ç: {usage.completion_tokens:,}")
        print(f"   –í—Å–µ–≥–æ: {usage.total_tokens:,}")
        
        return {
            'success': True,
            'data': parsed_data,
            'usage': {
                'prompt_tokens': usage.prompt_tokens,
                'completion_tokens': usage.completion_tokens,
                'total_tokens': usage.total_tokens
            },
            'raw_response': response.model_dump_json()
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ OpenAI API: {e}")
        return {
            'success': False,
            'error': str(e),
            'data': None
        }

def extract_expected_data():
    """–ò–∑–≤–ª–µ—á—å –æ–∂–∏–¥–∞–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–µ –∂–µ, —á—Ç–æ –¥–ª—è Markdown)"""
    return {
        'name': 'Ladydale Care Home',
        'cqc_location_id': '1-145996910',
        'city': 'Leek',
        'postcode': 'ST13 5LF',
        'address': '9 Fynney Street, Leek, Staffordshire',
        'care_residential': True,
        'care_respite': True,
        'care_dementia': False,
        'care_nursing': False,
        'provider_name': 'Pearlcare',
        'local_authority': 'Staffordshire',
        'cqc_rating_overall': 'Good',
        'beds_total': 54,
        'year_registered': 2011
    }

def compare_results(parsed_data: Dict, expected_data: Dict):
    """–°—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å –æ–∂–∏–¥–∞–µ–º—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    print("\n" + "="*80)
    print("üîç –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í (HTML vs –û–∂–∏–¥–∞–µ–º—ã–µ)")
    print("="*80)
    
    errors = []
    warnings = []
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
    identity = parsed_data.get('identity', {})
    location = parsed_data.get('location', {})
    
    # 1. name
    parsed_name = identity.get('name')
    expected_name = expected_data.get('name')
    if parsed_name != expected_name:
        errors.append(f"name: –æ–∂–∏–¥–∞–ª–æ—Å—å '{expected_name}', –ø–æ–ª—É—á–µ–Ω–æ '{parsed_name}'")
    else:
        print(f"‚úÖ name: {parsed_name}")
    
    # 2. cqc_location_id
    parsed_cqc_id = identity.get('cqc_location_id')
    expected_cqc_id = expected_data.get('cqc_location_id')
    if parsed_cqc_id != expected_cqc_id:
        errors.append(f"cqc_location_id: –æ–∂–∏–¥–∞–ª–æ—Å—å '{expected_cqc_id}', –ø–æ–ª—É—á–µ–Ω–æ '{parsed_cqc_id}'")
    else:
        print(f"‚úÖ cqc_location_id: {parsed_cqc_id}")
    
    # 3. city
    parsed_city = location.get('city')
    expected_city = expected_data.get('city')
    if parsed_city != expected_city:
        errors.append(f"city: –æ–∂–∏–¥–∞–ª–æ—Å—å '{expected_city}', –ø–æ–ª—É—á–µ–Ω–æ '{parsed_city}'")
    else:
        print(f"‚úÖ city: {parsed_city}")
    
    # 4. postcode
    parsed_postcode = location.get('postcode')
    expected_postcode = expected_data.get('postcode')
    if parsed_postcode != expected_postcode:
        errors.append(f"postcode: –æ–∂–∏–¥–∞–ª–æ—Å—å '{expected_postcode}', –ø–æ–ª—É—á–µ–Ω–æ '{parsed_postcode}'")
    else:
        print(f"‚úÖ postcode: {parsed_postcode}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä—É–≥–∏—Ö –ø–æ–ª–µ–π
    care_services = parsed_data.get('care_services', {})
    
    # care_residential
    parsed_residential = care_services.get('care_residential')
    expected_residential = expected_data.get('care_residential')
    if parsed_residential != expected_residential:
        warnings.append(f"care_residential: –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_residential}, –ø–æ–ª—É—á–µ–Ω–æ {parsed_residential}")
    else:
        print(f"‚úÖ care_residential: {parsed_residential}")
    
    # care_respite
    parsed_respite = care_services.get('care_respite')
    expected_respite = expected_data.get('care_respite')
    if parsed_respite != expected_respite:
        warnings.append(f"care_respite: –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_respite}, –ø–æ–ª—É—á–µ–Ω–æ {parsed_respite}")
    else:
        print(f"‚úÖ care_respite: {parsed_respite}")
    
    # care_dementia
    parsed_dementia = care_services.get('care_dementia')
    expected_dementia = expected_data.get('care_dementia')
    if parsed_dementia != expected_dementia:
        warnings.append(f"care_dementia: –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_dementia}, –ø–æ–ª—É—á–µ–Ω–æ {parsed_dementia}")
    else:
        print(f"‚úÖ care_dementia: {parsed_dementia}")
    
    # provider_name
    parsed_provider = identity.get('provider_name')
    expected_provider = expected_data.get('provider_name')
    if parsed_provider != expected_provider:
        warnings.append(f"provider_name: –æ–∂–∏–¥–∞–ª–æ—Å—å '{expected_provider}', –ø–æ–ª—É—á–µ–Ω–æ '{parsed_provider}'")
    else:
        print(f"‚úÖ provider_name: {parsed_provider}")
    
    # local_authority
    parsed_la = location.get('local_authority')
    expected_la = expected_data.get('local_authority')
    if parsed_la != expected_la:
        warnings.append(f"local_authority: –æ–∂–∏–¥–∞–ª–æ—Å—å '{expected_la}', –ø–æ–ª—É—á–µ–Ω–æ '{parsed_la}'")
    else:
        print(f"‚úÖ local_authority: {parsed_la}")
    
    # beds_total
    capacity = parsed_data.get('capacity', {})
    parsed_beds = capacity.get('beds_total')
    expected_beds = expected_data.get('beds_total')
    if parsed_beds != expected_beds:
        warnings.append(f"beds_total: –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_beds}, –ø–æ–ª—É—á–µ–Ω–æ {parsed_beds}")
    else:
        print(f"‚úÖ beds_total: {parsed_beds}")
    
    # year_registered
    parsed_year_reg = capacity.get('year_registered')
    expected_year_reg = expected_data.get('year_registered')
    if parsed_year_reg != expected_year_reg:
        warnings.append(f"year_registered: –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_year_reg}, –ø–æ–ª—É—á–µ–Ω–æ {parsed_year_reg}")
    else:
        print(f"‚úÖ year_registered: {parsed_year_reg}")
    
    # CQC rating
    cqc_ratings = parsed_data.get('cqc_ratings', {})
    parsed_rating = cqc_ratings.get('cqc_rating_overall') or cqc_ratings.get('overall_rating')
    expected_rating = expected_data.get('cqc_rating_overall')
    if parsed_rating != expected_rating:
        warnings.append(f"cqc_rating_overall: –æ–∂–∏–¥–∞–ª–æ—Å—å '{expected_rating}', –ø–æ–ª—É—á–µ–Ω–æ '{parsed_rating}'")
    else:
        print(f"‚úÖ cqc_rating_overall: {parsed_rating}")
    
    print("\n" + "="*80)
    if errors:
        print(f"‚ùå –û–®–ò–ë–ö–ò ({len(errors)}):")
        for error in errors:
            print(f"   - {error}")
    else:
        print("‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –∏–∑–≤–ª–µ—á–µ–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")
    
    if warnings:
        print(f"\n‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø ({len(warnings)}):")
        for warning in warnings:
            print(f"   - {warning}")
    else:
        print("\n‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–µ –ø–æ–ª—è –∏–∑–≤–ª–µ—á–µ–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")
    
    return {
        'errors': errors,
        'warnings': warnings,
        'total_errors': len(errors),
        'total_warnings': len(warnings)
    }

def main():
    html_file = "input/autumna/Data-MD/html 1 /test1-html.html"
    
    if not os.path.exists(html_file):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {html_file}")
        sys.exit(1)
    
    # –ü–∞—Ä—Å–∏–Ω–≥
    print("="*80)
    print("üß™ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢: –ü–ê–†–°–ò–ù–ì HTML –§–ê–ô–õ–ê")
    print("="*80)
    print("–¶–µ–ª—å: –°—Ä–∞–≤–Ω–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ HTML vs Markdown")
    print()
    
    result = parse_html_file(html_file)
    
    if not result['success']:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {result.get('error')}")
        sys.exit(1)
    
    parsed_data = result['data']
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    output_file = "input/autumna/Data-MD/html 1 /test1-html-parsed-result.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(parsed_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
    
    # –ò–∑–≤–ª–µ—á—å –æ–∂–∏–¥–∞–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ
    expected_data = extract_expected_data()
    
    # –°—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    comparison = compare_results(parsed_data, expected_data)
    
    # –í—ã–≤–µ—Å—Ç–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
    extraction_meta = parsed_data.get('extraction_metadata', {})
    print("\n" + "="*80)
    print("üìä –ú–ï–¢–ê–î–ê–ù–ù–´–ï –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø")
    print("="*80)
    print(f"   extraction_confidence: {extraction_meta.get('extraction_confidence', 'N/A')}")
    print(f"   data_quality_score: {extraction_meta.get('data_quality_score', 'N/A')}")
    print(f"   is_dormant: {extraction_meta.get('is_dormant', False)}")
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "="*80)
    print("üìà –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*80)
    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥: –î–∞")
    print(f"   ‚ùå –û—à–∏–±–∫–∏: {comparison['total_errors']}")
    print(f"   ‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {comparison['total_warnings']}")
    print(f"   üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {result['usage']['total_tokens']:,}")
    print(f"      - –ü—Ä–æ–º–ø—Ç: {result['usage']['prompt_tokens']:,}")
    print(f"      - –û—Ç–≤–µ—Ç: {result['usage']['completion_tokens']:,}")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
    html_size = len(open(html_file, 'r', encoding='utf-8').read())
    print(f"\nüìè –†–ê–ó–ú–ï–† –î–ê–ù–ù–´–•:")
    print(f"   HTML —Ñ–∞–π–ª: {html_size:,} —Å–∏–º–≤–æ–ª–æ–≤ (~{html_size // 4:,} —Ç–æ–∫–µ–Ω–æ–≤)")
    print(f"   –ü—Ä–æ–º–ø—Ç: ~6,400 —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"   –í—Å–µ–≥–æ –≤ –∑–∞–ø—Ä–æ—Å–µ: ~{result['usage']['prompt_tokens']:,} —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {result['usage']['prompt_tokens'] / 128000 * 100:.2f}%")
    
    print("\n" + "="*80)
    print("üí° –°–†–ê–í–ù–ï–ù–ò–ï HTML vs MARKDOWN:")
    print("="*80)
    print("   Markdown: ~10,062 —Å–∏–º–≤–æ–ª–æ–≤ (~2,515 —Ç–æ–∫–µ–Ω–æ–≤)")
    print(f"   HTML: {html_size:,} —Å–∏–º–≤–æ–ª–æ–≤ (~{html_size // 4:,} —Ç–æ–∫–µ–Ω–æ–≤)")
    print(f"   –†–∞–∑–Ω–∏—Ü–∞: {html_size / 10062:.1f}x –±–æ–ª—å—à–µ")
    print(f"   –¢–æ–∫–µ–Ω—ã HTML: ~{html_size // 4:,} vs Markdown: ~2,515")
    print(f"   –≠–∫–æ–Ω–æ–º–∏—è Markdown: ~{(html_size // 4 - 2515) / (html_size // 4) * 100:.1f}%")

if __name__ == '__main__':
    main()

